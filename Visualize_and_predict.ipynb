{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "#plt.legend(loc='best')\n",
    "\n",
    "from os.path import join, exists\n",
    "import pandas as pd\n",
    "from os import makedirs\n",
    "from datetime import date\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import treeinterpreter as ti\n",
    "from treeinterpreter import treeinterpreter as ti\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "    \n",
    "\n",
    "def return_combined(start_date = date(2000,1, 1),end_date=date(2000,2, 1)):\n",
    "    stock_file = join('data/stock_data', start_date.strftime('%Y-%m-%d') +'::'+ end_date.strftime('%Y-%m-%d') + '.pkl')\n",
    "    polarities_file =  join('data/sentiment_data', start_date.strftime('%Y-%m-%d') +'::'+ end_date.strftime('%Y-%m-%d') + '.pkl')\n",
    "    df_stock = pd.read_pickle(stock_file) \n",
    "    df_polarities = pd.read_pickle(polarities_file) \n",
    "\n",
    "\n",
    "    date_range = pd.date_range(start_date, end_date)\n",
    "\n",
    "    df_stock = df_stock.reindex(date_range, fill_value=np.NaN)\n",
    "    df_stock = df_stock.interpolate()\n",
    "    df_polarities.index = pd.DatetimeIndex(df_polarities.publicationDate)\n",
    "    df_polarities = df_polarities.groupby(by = [df_polarities.index,'sectionId']).mean()\n",
    "\n",
    "    df_polarities = df_polarities.unstack()\n",
    "\n",
    "\n",
    "    df_polarities = df_polarities.xs('polarity', axis=1, drop_level=True)\n",
    "    df_polarities.reset_index(inplace=True)\n",
    "    df_polarities.set_index('publicationDate', inplace=True)\n",
    "    df_polarities= df_polarities[['world','business','politics','technology','money','media']]\n",
    "    \n",
    "    df_combined = df_stock.join(df_polarities)\n",
    "    df_combined = df_combined.fillna(method ='bfill')\n",
    "    df_combined = df_combined.fillna(method ='ffill')\n",
    "    return df_combined \n",
    "\n",
    "\n",
    "def visualize_polarity(start_date = date(2000,1, 1),end_date=date(2000,2, 1)): \n",
    "\n",
    "    #DATAFRAME_DIR = join('data' ,'dataframes')\n",
    "    #makedirs(DATAFRAME_DIR, exist_ok=True)\n",
    "    \n",
    "    stock_file = join('data/stock_data', start_date.strftime('%Y-%m-%d') +'::'+ end_date.strftime('%Y-%m-%d') + '.pkl')\n",
    "    polarities_file =  join('data/sentiment_data', start_date.strftime('%Y-%m-%d') +'::'+ end_date.strftime('%Y-%m-%d') + '.pkl')\n",
    "    \n",
    "    \n",
    "    df_stock = pd.read_pickle(stock_file) \n",
    "    df_polarities = pd.read_pickle(polarities_file) \n",
    "   \n",
    "    \n",
    "    df_polarities.index = pd.DatetimeIndex(df_polarities.publicationDate)\n",
    "    df_polarities = df_polarities.groupby(by = [df_polarities.index,'sectionId']).mean()\n",
    "\n",
    "    df_polarities = df_polarities.unstack()\n",
    "\n",
    "\n",
    "    df_polarities = df_polarities.xs('polarity', axis=1, drop_level=True)\n",
    "    df_polarities.reset_index(inplace=True)\n",
    "    df_polarities.set_index('publicationDate', inplace=True)\n",
    "    df_polarities= df_polarities[['world','business','politics','technology','money','media']]\n",
    "\n",
    "       \n",
    "    values = df_polarities.values\n",
    "    groups = [0,1,2,3,4,5]\n",
    "    n = 1 \n",
    "\n",
    "    pyplot.figure(figsize=(20,10))\n",
    "    for group in groups:\n",
    "        pyplot.subplot(len(groups), 1, n)\n",
    "        pyplot.plot(values[:, group])\n",
    "        pyplot.title(df_polarities.columns[group], y=0.5, loc='right')\n",
    "        n += 1\n",
    "    pyplot.show()\n",
    "    return df_polarities \n",
    "\n",
    "\n",
    "    #df_combined = df.join(df_sentiment_scores)\n",
    "    #df_combined = df_combined.fillna(method='ffill')  #ffill: propagate last valid observation forward to next valid \" \n",
    "    #df_combined = df_combined.fillna(method ='bfill')  # one missing for 'money section \n",
    "    \n",
    "def visualize_stocks(start_date = date(2000,1, 1),end_date=date(2000,2, 1)): \n",
    "    \n",
    "    stock_file = join('data/stock_data', start_date.strftime('%Y-%m-%d') +'::'+ end_date.strftime('%Y-%m-%d') + '.pkl')\n",
    "\n",
    "    df_stocks = pd.read_pickle(stock_file) \n",
    "    date_range = pd.date_range(start_date, end_date)\n",
    "    df_stocks = df_stocks.reindex(date_range, fill_value=np.NaN)\n",
    "    df_stocks= df_stocks.interpolate()\n",
    "\n",
    "    values = df_stocks.values\n",
    "    groups = [0,1,2,3,4]\n",
    "    #values = values.astype('float32')\n",
    "    n = 1 \n",
    "    pyplot.figure(figsize=(20,10))\n",
    "    for group in groups:\n",
    "        pyplot.subplot(len(groups), 1, n)\n",
    "        pyplot.plot(values[:, group])\n",
    "        pyplot.title(df_stocks.columns[group], y=0.5, loc='right')\n",
    "        n += 1\n",
    "    pyplot.show()\n",
    "    return df_stocks\n",
    "\n",
    "def visualize_correlation(start_date = date(2000,1, 1),end_date=date(2000,2, 1)):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    df_combined = return_combined(start,end)\n",
    "\n",
    "    sns.set(style=\"dark\")\n",
    "\n",
    "    df = df_combined.pct_change()\n",
    "    corr = df.corr()\n",
    "    np_mask = np.zeros_like(corr, dtype=np.bool)\n",
    "    np_mask[np.triu_indices_from(np_mask)] = True\n",
    "    \n",
    "    f, ax = plt.subplots(figsize=(10, 9))\n",
    "    cmap = sns.diverging_palette(300, 10, as_cmap=True)\n",
    "\n",
    "    sns.heatmap(corr, mask=np_mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "    \n",
    "    return df_combined\n",
    "\n",
    "def visualize_prediction(start_date = date(2000,1, 1),end_date=date(2000,2, 1)): \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    df_combined = return_combined(start_date,end_date)\n",
    "    #df_combined.business = df_combined.business.pct_change()\n",
    "    #df_combined.money = df_combined.money.pct_change()\n",
    "    #df_combined.world = df_combined.world.pct_change()\n",
    "    df_combined = df_combined.fillna(method ='bfill')\n",
    "    df_combined = df_combined.fillna(method ='ffill')\n",
    "    #df_combined.dropna(inplace=True)\n",
    "    df_combined['sp_500'] = df_combined['sp_500'].apply(np.int64)\n",
    "\n",
    "    train_start = '2010-01-01'\n",
    "    train_end = '2010-08-01'\n",
    "    test_start = '2010-08-05'\n",
    "    test_end = '2010-12-24'\n",
    "    #df_combined['sp_500'] = df_combined['sp_500'].apply(np.int64)\n",
    "    train = df_combined.ix[train_start : train_end]\n",
    "    test = df_combined.ix[test_start:test_end]\n",
    "\n",
    "\n",
    "\n",
    "    prediction_list = []\n",
    "\n",
    "    sentiment_score_list = []\n",
    "    for date, row in train.T.iteritems():\n",
    "    #sentiment_score = np.asarray([df_combined.loc[date, 'business'],df_combined.loc[date, 'money'],df_combined.loc[date, 'world']])\n",
    "        sentiment_score = np.asarray([df_combined.loc[date, 'money']])\n",
    "        sentiment_score_list.append(sentiment_score)\n",
    "        numpy_df_train = np.asarray(sentiment_score_list)\n",
    "        \n",
    "    \n",
    "    sentiment_score_list = []\n",
    "    for date, row in test.T.iteritems():\n",
    "    #sentiment_score = np.asarray([df_combined.loc[date, 'business'],df_combined.loc[date, 'money'],df_combined.loc[date, 'world']])\n",
    "        sentiment_score = np.asarray([df_combined.loc[date, 'money']])\n",
    "        sentiment_score_list.append(sentiment_score)\n",
    "        numpy_df_test = np.asarray(sentiment_score_list)\n",
    "        \n",
    "    y_train = pd.DataFrame(train['sp_500'])\n",
    "    y_test = pd.DataFrame(test['sp_500'])\n",
    "    \n",
    "    rf = RandomForestRegressor()\n",
    "    rf.fit(numpy_df_train, y_train)\n",
    "\n",
    "\n",
    "    #print (rf.feature_importances_)\n",
    "    prediction, bias, contributions = ti.predict(rf, numpy_df_test)\n",
    "\n",
    "    idx = pd.date_range(test_start, test_end)\n",
    "    predictions_df = pd.DataFrame(data=prediction[0:], index = idx, columns=['sp500_predicted'])\n",
    "    #predictions_df\n",
    "\n",
    "    predictions_plot = predictions_df.plot()\n",
    "\n",
    "    fig = y_test.plot(ax = predictions_plot).get_figure()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lovelace/software/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/__main__.py:163: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "/mnt/lovelace/software/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/__main__.py:189: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-565b527a57f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#run_2 = visualize_polarity(start,end)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcombined\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mvisualize_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-73-d1895e1ddbfe>\u001b[0m in \u001b[0;36mvisualize_prediction\u001b[0;34m(start_date, end_date)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;31m#print (rf.feature_importances_)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontributions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mti\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy_df_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/lovelace/software/anaconda/envs/py35/lib/python3.5/site-packages/treeinterpreter/treeinterpreter.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model, X, joint_contribution)\u001b[0m\n\u001b[1;32m    201\u001b[0m     elif (type(model) == RandomForestRegressor or\n\u001b[1;32m    202\u001b[0m           type(model) == RandomForestClassifier):\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_predict_forest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoint_contribution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoint_contribution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         raise ValueError(\"Wrong model type. Base learner needs to be \\\n",
      "\u001b[0;32m/mnt/lovelace/software/anaconda/envs/py35/lib/python3.5/site-packages/treeinterpreter/treeinterpreter.py\u001b[0m in \u001b[0;36m_predict_forest\u001b[0;34m(model, X, joint_contribution)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_predict_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mbiases\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/lovelace/software/anaconda/envs/py35/lib/python3.5/site-packages/treeinterpreter/treeinterpreter.py\u001b[0m in \u001b[0;36m_predict_tree\u001b[0;34m(model, X, joint_contribution)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mthat\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m≈\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeature_contributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \"\"\"\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mleaves\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_tree_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/lovelace/software/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0mnumbering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \"\"\"\n\u001b[0;32m--> 456\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/lovelace/software/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n\u001b[1;32m    367\u001b[0m                                 X.indptr.dtype != np.intc):\n",
      "\u001b[0;32m/mnt/lovelace/software/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/lovelace/software/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "start = date(2010,1, 1)\n",
    "end = date(2010,12, 31)\n",
    "#compile_stock_indices(start,end)\n",
    "#compile_sentiment_scores(start,end)\n",
    "#run = visualize_stocks(start,end)\n",
    "#run_2 = visualize_polarity(start,end)\n",
    "\n",
    "combined= visualize_prediction(start,end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matplotlib.style.use('ggplot')\n",
    "# get ipython notebook to show graphs\n",
    "%pylab inline\n",
    "\n",
    "daily_returns= df_combined[['dow_jones','world','business','politics','technology','money','commentisfree','media']]\n",
    "\n",
    "rolling_correlation = pd.rolling_corr(daily_returns.dow_jones, daily_returns.money ,window=200).dropna()\n",
    "rolling_correlation.plot()\n",
    "plt.axhline(0, color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_combined = run.join(run_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.isnull().values.any()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined.money = combined.money.pct_change()\n",
    "\n",
    "combined = combined.fillna(method ='bfill')\n",
    "combined = combined.fillna(method ='ffill')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined = combined.fillna(method ='bfill')\n",
    "combined = combined.fillna(method ='ffill')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
